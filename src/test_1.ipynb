{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5d915c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (98482, 34)\n",
      "Class distribution (%):\n",
      "cdm_historical\n",
      "0.0    36.22\n",
      "2.0    31.13\n",
      "1.0    26.05\n",
      "3.0     6.60\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Split sizes:\n",
      "Train: (68937, 26)\n",
      "Val  : (14772, 26)\n",
      "Test : (14773, 26)\n",
      "Any NaN in X_train_enc? False\n",
      "\n",
      "Top 20 Features (Mutual Information):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>mi_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dist_snowice</td>\n",
       "      <td>0.311836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>dist_roads</td>\n",
       "      <td>0.253942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dist_crop</td>\n",
       "      <td>0.247116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mrsos</td>\n",
       "      <td>0.236514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lai</td>\n",
       "      <td>0.222481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>evspsbl</td>\n",
       "      <td>0.211614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hurs</td>\n",
       "      <td>0.188001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mrro</td>\n",
       "      <td>0.175908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rsds</td>\n",
       "      <td>0.172452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tg_mean</td>\n",
       "      <td>0.165153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cdd</td>\n",
       "      <td>0.161456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dem</td>\n",
       "      <td>0.151655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>soil_order</td>\n",
       "      <td>0.141910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sfcWind</td>\n",
       "      <td>0.125806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>dist_urban</td>\n",
       "      <td>0.121803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>r10mm</td>\n",
       "      <td>0.108888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>prcptot</td>\n",
       "      <td>0.104829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>lithology</td>\n",
       "      <td>0.100659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>soil_texture</td>\n",
       "      <td>0.085770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rlds</td>\n",
       "      <td>0.083297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature  mi_score\n",
       "3   dist_snowice  0.311836\n",
       "20    dist_roads  0.253942\n",
       "19     dist_crop  0.247116\n",
       "9          mrsos  0.236514\n",
       "7            lai  0.222481\n",
       "5        evspsbl  0.211614\n",
       "6           hurs  0.188001\n",
       "8           mrro  0.175908\n",
       "13          rsds  0.172452\n",
       "16       tg_mean  0.165153\n",
       "1            cdd  0.161456\n",
       "2            dem  0.151655\n",
       "25    soil_order  0.141910\n",
       "14       sfcWind  0.125806\n",
       "21    dist_urban  0.121803\n",
       "11         r10mm  0.108888\n",
       "10       prcptot  0.104829\n",
       "23     lithology  0.100659\n",
       "24  soil_texture  0.085770\n",
       "12          rlds  0.083297"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashkan/miniconda3/envs/drought/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Results\n",
      "Accuracy: 0.6164178887970175\n",
      "Balanced Accuracy: 0.650905305462292\n",
      "F1 (macro): 0.5863052879302222\n",
      "[[19733  3408  1472   357]\n",
      " [ 3242  8715  4303  1698]\n",
      " [ 1435  5444 10156  4423]\n",
      " [    0   136   525  3890]]\n",
      "\n",
      "Validation Results\n",
      "Accuracy: 0.6157595450852965\n",
      "Balanced Accuracy: 0.6516078921997771\n",
      "F1 (macro): 0.5856016922220224\n",
      "[[4244  719  291   96]\n",
      " [ 666 1829  972  381]\n",
      " [ 323 1170 2180  925]\n",
      " [   0   27  106  843]]\n",
      "\n",
      "Test Results\n",
      "Accuracy: 0.6213362214851418\n",
      "Balanced Accuracy: 0.6577099807235322\n",
      "F1 (macro): 0.5932207119284232\n",
      "[[4236  747  269   99]\n",
      " [ 686 1882  887  393]\n",
      " [ 318 1230 2214  837]\n",
      " [   0   21  107  847]]\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 0) Imports & Reproducibility\n",
    "# =====================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(RANDOM_STATE)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 1) Load Data\n",
    "# =====================================================\n",
    "DATA_PATH = \"historical_2003-2014.csv\"\n",
    "TARGET_COL = \"cdm_historical\"\n",
    "\n",
    "ID_COLS = [\"point_id\", \"lat_dd\", \"long_dd\"]\n",
    "AUX_COLS = [\"gdp\", \"pop\", \"cdm_model\", \"cdm_p_value\"]\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# فقط داده‌های برچسب‌دار\n",
    "df = df[df[TARGET_COL].notna()].copy()\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Class distribution (%):\")\n",
    "print(df[TARGET_COL].value_counts(normalize=True).mul(100).round(2))\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 2) Feature Definition\n",
    "# =====================================================\n",
    "CATEGORICAL_COLS = [\n",
    "    \"lulc\",\n",
    "    \"lithology\",\n",
    "    \"soil_texture\",\n",
    "    \"soil_order\",\n",
    "]\n",
    "\n",
    "NUMERICAL_COLS = [\n",
    "    \"aspect\", \"cdd\", \"dem\",\n",
    "    \"dist_snowice\", \"dist_water\",\n",
    "    \"evspsbl\", \"hurs\", \"lai\",\n",
    "    \"mrro\", \"mrsos\", \"prcptot\",\n",
    "    \"r10mm\", \"rlds\", \"rsds\",\n",
    "    \"sfcWind\", \"slope\",\n",
    "    \"tg_mean\", \"tx_max\", \"txgt_30\",\n",
    "    \"dist_crop\", \"dist_roads\", \"dist_urban\",\n",
    "]\n",
    "\n",
    "ALL_FEATURES = NUMERICAL_COLS + CATEGORICAL_COLS\n",
    "\n",
    "X = df[ALL_FEATURES]\n",
    "y = df[TARGET_COL].astype(int)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 3) Train / Validation / Test Split (70 / 15 / 15)\n",
    "# =====================================================\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.80,\n",
    "    stratify=y,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.50,\n",
    "    stratify=y_temp,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"\\nSplit sizes:\")\n",
    "print(\"Train:\", X_train.shape)\n",
    "print(\"Val  :\", X_val.shape)\n",
    "print(\"Test :\", X_test.shape)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 4) Encoding categorical + Imputation (for MI only)\n",
    "# =====================================================\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X_train_enc = X_train.copy()\n",
    "X_val_enc   = X_val.copy()\n",
    "X_test_enc  = X_test.copy()\n",
    "\n",
    "# --- categorical → integer codes ---\n",
    "for col in CATEGORICAL_COLS:\n",
    "    X_train_enc[col] = X_train_enc[col].astype(\"category\").cat.codes\n",
    "    X_val_enc[col]   = X_val_enc[col].astype(\"category\").cat.codes\n",
    "    X_test_enc[col]  = X_test_enc[col].astype(\"category\").cat.codes\n",
    "\n",
    "# --- numerical imputation (median, TRAIN only) ---\n",
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "X_train_enc[NUMERICAL_COLS] = num_imputer.fit_transform(\n",
    "    X_train_enc[NUMERICAL_COLS]\n",
    ")\n",
    "X_val_enc[NUMERICAL_COLS] = num_imputer.transform(\n",
    "    X_val_enc[NUMERICAL_COLS]\n",
    ")\n",
    "X_test_enc[NUMERICAL_COLS] = num_imputer.transform(\n",
    "    X_test_enc[NUMERICAL_COLS]\n",
    ")\n",
    "\n",
    "# sanity\n",
    "print(\"Any NaN in X_train_enc?\", X_train_enc.isna().any().any())\n",
    "\n",
    "# =====================================================\n",
    "# 5) Mutual Information — Top 20 (TRAIN ONLY)\n",
    "# =====================================================\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "mi_scores = mutual_info_classif(\n",
    "    X_train_enc,\n",
    "    y_train,\n",
    "    random_state=RANDOM_STATE,\n",
    "    discrete_features=[c in CATEGORICAL_COLS for c in X_train_enc.columns]\n",
    ")\n",
    "\n",
    "mi_df = pd.DataFrame({\n",
    "    \"feature\": X_train_enc.columns,\n",
    "    \"mi_score\": mi_scores\n",
    "}).sort_values(\"mi_score\", ascending=False)\n",
    "\n",
    "TOP_K = 10\n",
    "TOP_FEATURES = mi_df.head(TOP_K)[\"feature\"].tolist()\n",
    "\n",
    "print(\"\\nTop 10 Features (Mutual Information):\")\n",
    "display(mi_df.head(TOP_K))\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 6) Reduce Feature Space\n",
    "# =====================================================\n",
    "X_train_fs = X_train_enc[TOP_FEATURES]\n",
    "X_val_fs   = X_val_enc[TOP_FEATURES]\n",
    "X_test_fs  = X_test_enc[TOP_FEATURES]\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 7) Logistic Regression Baseline\n",
    "# =====================================================\n",
    "lr_pipeline = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        max_iter=300,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1,\n",
    "        multi_class=\"auto\",\n",
    "        random_state=RANDOM_STATE\n",
    "    ))\n",
    "])\n",
    "\n",
    "lr_pipeline.fit(X_train_fs, y_train)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 8) Evaluation\n",
    "# =====================================================\n",
    "def evaluate(model, X, y, name):\n",
    "    pred = model.predict(X)\n",
    "    print(f\"\\n{name} Results\")\n",
    "    print(\"Accuracy:\", accuracy_score(y, pred))\n",
    "    print(\"Balanced Accuracy:\", balanced_accuracy_score(y, pred))\n",
    "    print(\"F1 (macro):\", f1_score(y, pred, average=\"macro\"))\n",
    "    print(confusion_matrix(y, pred))\n",
    "\n",
    "\n",
    "evaluate(lr_pipeline, X_train_fs, y_train, \"Train\")\n",
    "evaluate(lr_pipeline, X_val_fs, y_val, \"Validation\")\n",
    "evaluate(lr_pipeline, X_test_fs, y_test, \"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eea1df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190e2bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ffb155",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drought",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
